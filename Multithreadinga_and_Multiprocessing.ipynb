{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b22aa4-4cbc-41a4-876a-34a5196e8910",
   "metadata": {},
   "source": [
    "# Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c02f82-c5ea-4e91-8b54-cccb44c991fd",
   "metadata": {},
   "source": [
    "Generators are function that return an object that can be iterated over. The special thing is that they generate the items inside the object lazily, which means they generate the items only one at a time and only when you ask for it. And because of this, they are much more memory efficient than other sequence objects when you have to deal with large data sets. They are a powerful advanced Python technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab9df93-6b5b-4068-8e0e-80615e45ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def mygenerator():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3\n",
    "\n",
    "for i in mygenerator():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3b86a-d21a-4117-aeba-8c8fdf95aa4b",
   "metadata": {},
   "source": [
    "Let's have a closer look at the execution. This can be visualized by another generator. The generator is memory efficient because, instead of predefining the values of an iterable collection, it gives the possibility to calculate a value of an index when it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "209da9a9-64eb-4216-a46f-f1779d8f63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8448728\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Lists object generator\n",
    "def firstn(n):\n",
    "    nums = []\n",
    "    num = 0\n",
    "    while num < n:\n",
    "        nums.append(num)\n",
    "        num+=1\n",
    "    return nums\n",
    "\n",
    "# Generator object of collection\n",
    "def firstn_generator(n):\n",
    "    num = 0\n",
    "    while num < n:\n",
    "        yield num\n",
    "        num += 1\n",
    "\n",
    "print(sys.getsizeof(firstn(1000000)))\n",
    "print(sys.getsizeof(firstn_generator(1000000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130ce0b-8f15-4dae-b95c-39f19b13814e",
   "metadata": {},
   "source": [
    "We can see that a generator is orders of magnitude more efficient. Furthermore, we don't have to wait for the operating system to read all the data into the memory before we can use the collection, so it is faster as well. Consequently, generators are very handy, when the collection data can be determined from known patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ee0ec-d3f9-4780-b0bc-97c02cbe4e3d",
   "metadata": {},
   "source": [
    "Generator expressions are handier still. They are written like list comprehensions, but with parentheses instead of square brackets. It is a very simple syntax and shortcut to implement the generator expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aaade377-b596-47c2-9782-2d84cb572f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of generator is:  208\n",
      "Size of list is:  444376\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Using expression as generator definition\n",
    "mygenerator = (i for i in range(100000) if i % 2 == 0)\n",
    "print(\"Size of generator is: \", sys.getsizeof(mygenerator))\n",
    "\n",
    "# Using expression as list definition\n",
    "mylist = [i for i in range(100000) if i % 2 == 0]\n",
    "print(\"Size of list is: \", sys.getsizeof(mylist))\n",
    "\n",
    "sum = 0\n",
    "for i in mygenerator:\n",
    "    sum += 1\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad6e1c-c7f5-4718-b2ae-a1b03e7360b7",
   "metadata": {},
   "source": [
    "# Threading vs Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df7952-e85e-4cdc-841d-99db094f6d35",
   "metadata": {},
   "source": [
    "## Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92ee16-174d-4728-b19d-c148cf70262f",
   "metadata": {},
   "source": [
    "A thread is an entity within a process that can be scheduled for execution. All threads within a process share the same memory space, which allows them to communicate quickly but also requires careful management to avoid conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df92caa-9d63-4a8c-a236-4ac74085b1b9",
   "metadata": {},
   "source": [
    "| Pros                                         | Explanation                                                                                     | Cons                                    | Explanation                                                                                     |\n",
    "|----------------------------------------------|--------------------------------------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| All threads within a process share the same memory | This allows threads to communicate quickly and share data easily.                                | Threading is limited by GIL: Only one thread at a time | In Python, the Global Interpreter Lock (GIL) means that only one thread can execute Python bytecode at a time, limiting concurrency. |\n",
    "| Lightweight                                  | Threads use fewer resources and less overhead than processes.                                    | No effect for CPU-bound tasks           | For CPU-bound tasks, threads do not provide performance improvements due to the GIL.             |\n",
    "| Starting a thread is faster than starting a process | Creating a thread incurs less overhead compared to creating a process.                           | Not interruptable/killable              | Threads cannot be forcibly terminated from the outside; they must complete their task.           |\n",
    "| Great for I/O-bound tasks                    | Threads can handle multiple I/O operations concurrently, improving performance.                  | Careful with race conditions            | Shared memory access can lead to race conditions if not managed properly.                        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a94f95-dd68-43f0-88ee-26361668d6d1",
   "metadata": {},
   "source": [
    "**When to Use Threads:**\n",
    "\n",
    "- *I/O-bound tasks:* Threads are excellent for tasks that spend a lot of time waiting for I/O operations, such as reading from a disk, network communication, or user inputs.\n",
    "- *Lightweight operations:* When you need to perform many small tasks simultaneously, threads are more efficient because they require less overhead to create and manage.\n",
    "- *Quick startup time:* If your application needs to start many parallel tasks quickly, threads are advantageous due to their fast startup time compared to processes.\n",
    "\n",
    "**Avoid Threads:**\n",
    "\n",
    "- *CPU-bound tasks:* Due to the Global Interpreter Lock (GIL) in Python, threads are not suitable for CPU-bound tasks because only one thread can execute Python code at a time.\n",
    "- *High control needs:* If you need to be able to forcibly stop a task, threads are not ideal since they cannot be interrupted or killed externally.\n",
    "- *Complex synchronization:* If your tasks require complex sharing and synchronization of data, the potential for race conditions and the complexity of managing thread safety might outweigh the benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b346dd47-399a-4048-9f0e-45fe23659c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end main\n"
     ]
    }
   ],
   "source": [
    "# Import the basic threading library\n",
    "from threading import Thread\n",
    "import os\n",
    "import time\n",
    "\n",
    "# A good number of processes is the number of threads\n",
    "threads = []\n",
    "num_threads = 10\n",
    "\n",
    "# We have to define a function to use a process\n",
    "def square_numbers():\n",
    "    for i in range(100):\n",
    "        i * i\n",
    "\n",
    "# Assigning process to the function\n",
    "for i in range(num_threads):\n",
    "    t = Thread(target=square_numbers)\n",
    "    threads.append(t)\n",
    "\n",
    "# Start each thread\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# Block the main thread until the processes are finished\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print('end main')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04277a82-7105-4a4b-9245-13802cf21bf1",
   "metadata": {},
   "source": [
    "Since threads live in the same memory space, sharing data is easy. We can do it in Python using a global variable. This variable simulates a database. We have to be careful through, as database integrity can be easily affected by interferennce. Therefore we have to use syncronization methods. For this special locks are used before and after processing the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb4824-d8d5-4160-a6ba-f36b43f5dc48",
   "metadata": {},
   "source": [
    "In addition a queue can be used for data interference. A queue is a linear data structure similar to a FIFO. This avoids discriminating threads from getting the lock. Note that any input or output stream has to be used as a database as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5f0c40a9-5c57-4e5c-9c77-370135b139db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End value of database:  2\n"
     ]
    }
   ],
   "source": [
    "# Import special type for lock\n",
    "from threading import Lock\n",
    "\n",
    "database_value = 0\n",
    "\n",
    "def increase(lock):\n",
    "    global database_value\n",
    "\n",
    "    # Another thread cannot have it the same time\n",
    "    with lock:\n",
    "        local_copy = database_value\n",
    "        local_copy += 1\n",
    "        time.sleep(0.03)\n",
    "        database_value = local_copy\n",
    "\n",
    "# Creating threads\n",
    "lock = Lock()\n",
    "thread1 = Thread(target=increase, args=(lock,))\n",
    "thread2 = Thread(target=increase, args=(lock,))\n",
    "\n",
    "# Starting threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Stopping threads\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"End value of database: \", database_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e87838-89c4-4b35-8317-e3caa33f54ff",
   "metadata": {},
   "source": [
    "While the main thread is the initial thread of execution in any Python program, as when a Python script starts, a single main thread is created by default, the daemon thread is a type of thread that runs in the background and is typically used for tasks that should not block the program from exiting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d724f83-567d-4b4b-adc2-ecacbf28a080",
   "metadata": {},
   "source": [
    "| Aspect           | Main Thread                                              | Daemon Thread                                            |\n",
    "|------------------|----------------------------------------------------------|----------------------------------------------------------|\n",
    "| **Role**         | Handles the primary logic and essential tasks.           | Handles background tasks like logging and monitoring.    |\n",
    "| **Lifecycle**    | Program runs until the main thread finishes.             | Program exits when only daemon threads are left running. |\n",
    "| **Termination**  | Prevents program from exiting until it completes.        | Does not prevent program from exiting.                   |\n",
    "| **Creation**     | Automatically created when the program starts.           | Created by setting `daemon` attribute to `True` before starting the thread. |\n",
    "| **Usage**        | Used for core application logic and critical operations. | Used for periodic or auxiliary tasks that can terminate abruptly. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5c86a-e533-4dc2-b8dc-84aaeffa6a7c",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64966d35-5c54-428e-8d0f-f3e50eca3a64",
   "metadata": {},
   "source": [
    "A process is an instance of a program running in its own memory space. Each process is independent and isolated from others, which provides stability and security but requires more resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9759e3-5428-4453-be78-0d0a399f9483",
   "metadata": {},
   "source": [
    "| Pros                                               | Explanation                                                                                     | Cons                                               | Explanation                                                                                     |\n",
    "|----------------------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| Takes advantage of multiple CPUs and cores         | Processes can run on different CPUs or cores, providing true parallelism.                       | Heavyweight                                        | Processes use more system resources and are heavier than threads.                               |\n",
    "| Separate memory space -> Memory is not shared between processes | Each process has its own memory space, which enhances stability and security.                   | Starting a process is slower than starting a thread | Creating a new process takes more time and resources compared to a thread.                      |\n",
    "| Great for CPU-bound processing                     | Processes can fully utilize multiple cores for CPU-intensive tasks.                             | More memory                                        | Each process requires its own memory allocation, leading to higher memory usage.                |\n",
    "| New process is started independently from other processes | Processes are isolated, so the failure of one does not affect others.                            | IPC (inter-process communication) is more complicated | Communicating between processes is more complex and requires additional mechanisms.              |\n",
    "| Processes are interruptable/killable               | Processes can be terminated externally, allowing for better control.                            |                                                    |                                                                                                  |\n",
    "| One GIL for each process -> avoids GIL limitation  | Each process has its own GIL, so they can run Python code concurrently.                         |                                                    |                                                                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8c757-ba71-4b15-97a3-50fb710a1ad8",
   "metadata": {},
   "source": [
    "**When to Use Processes:**\n",
    "\n",
    "- *CPU-bound tasks:* Processes can fully utilize multiple CPU cores because each process runs independently and has its own Python interpreter and GIL.\n",
    "- *Memory isolation:* If you need tasks to run in isolated memory spaces to avoid conflicts and improve stability, processes are the better choice.\n",
    "- *Parallel execution:* For true parallel execution on multiple cores, processes are necessary.\n",
    "\n",
    "**Avoid Processes:**\n",
    "\n",
    "- *I/O-bound tasks:* The overhead of creating and managing processes can be too high for tasks that spend a lot of time waiting for I/O operations.\n",
    "- *Resource efficiency:* If you need to run many tasks simultaneously with minimal overhead, the resource demands of processes may be too high.\n",
    "- *Complex IPC:* Communication between processes is more complicated than between threads, which can add complexity to your application if frequent inter-process communication is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "31b72b91-1ea2-4eb9-9aa4-8460aa09960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end main\n"
     ]
    }
   ],
   "source": [
    "# basic multiprocessing library\n",
    "from multiprocessing import Process\n",
    "\n",
    "# A good number of processes is the number of cores\n",
    "processes = []\n",
    "num_processes = os.cpu_count()\n",
    "\n",
    "# Assigning process to the function\n",
    "for i in range(num_processes):\n",
    "    p = Process(target=square_numbers)\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "# Block the main thread until the processes are finished\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "print('end main')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325fe72-5f74-4b02-bcb8-ff2e0c37d528",
   "metadata": {},
   "source": [
    "Sharing data is a little more complicated, but Python Value or Array module simplifies it a lot. \n",
    "- The Value class allows you to create a shared object that can be accessed by multiple processes. This is useful for sharing simple data types such as integers or floats.\n",
    "- The Array class allows you to create a shared array of fixed size. This is useful for sharing a list-like structure between processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0ec34c1d-7cf2-4dd8-88a1-2a3197afd11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value and Array is imported from multiprocessing\n",
    "from multiprocessing import Value, Array, Lock, Queue\n",
    "\n",
    "def square(numbers, queue):\n",
    "    for i in numbers: \n",
    "        queue.put(i*i)\n",
    "\n",
    "def make_negative(numbers, queue):\n",
    "    for i in numbers:\n",
    "        queue.put(-1*i)\n",
    "\n",
    "numbers = range(1, 6)\n",
    "shared_queue = Queue()\n",
    "\n",
    "p1 = Process(target=square, args=(numbers,shared_queue))\n",
    "p2 = Process(target=make_negative, args=(numbers,shared_queue))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "\n",
    "p1.join()\n",
    "p2.join()\n",
    "\n",
    "while not shared_queue.empty():\n",
    "    print(shared_queue.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451aebb-966d-48e9-be9a-7f362bc1fa67",
   "metadata": {},
   "source": [
    "Process pools, provided by the multiprocessing module in Python, are a way to manage a pool of worker processes that can execute tasks concurrently. This abstraction simplifies the process of parallel execution by managing the creation, distribution, and synchronization of tasks among multiple processes. The main class used for this purpose is Pool:\n",
    "- *Concurrent Execution*: Allows multiple tasks to be executed in parallel using multiple processes.\n",
    "- *Task Distribution*: Automatically distributes tasks among the available worker processes.\n",
    "- *Result Collection:* Collects results from the worker processes and returns them to the main process.\n",
    "- Task Management: Handles process creation, task assignment, and result retrieval, reducing boilerplate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074eb5c-a06a-4c64-92fb-571a6b7780b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def cube(number):\n",
    "    return number * number * number\n",
    "\n",
    "numbers = range(10)\n",
    "pool = Pool()\n",
    "\n",
    "# Automatically allocate the maximum number of available processes\n",
    "# Then it will split iteratble to equal sized chunks and executes it in parallel\n",
    "result = pool.map(cube, numbers)\n",
    "\n",
    "# Executes a process with one argument\n",
    "pool.apply(cube, number[0])\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f433031-100e-4f96-a85c-3428ce04f321",
   "metadata": {},
   "source": [
    "# Function Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ce30e-c0d1-4e7e-a72d-42274c828d19",
   "metadata": {},
   "source": [
    "## The difference between arguments and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a4001-bc9c-4864-a638-aec440837be3",
   "metadata": {},
   "source": [
    "In programming, especially in the context of functions, the terms \"arguments\" and \"parameters\" are often used interchangeably, but they have distinct meanings. Here’s a breakdown of the differences:\n",
    "- **Parameters** are the variables listed in a function's definition. They act as placeholders for the values that will be passed to the function.\n",
    "- **Arguments** are the actual values or data you pass into the function when you call it.\n",
    "They are the concrete values that get substituted for the function's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0a06c9-14a6-4249-96f9-1c029c2da687",
   "metadata": {},
   "source": [
    "In Python, function arguments can be passed in two main ways: positional arguments and keyword arguments. **Positional arguments** are arguments that are passed to a function in a specific order, the position of the argument in the function call determines which parameter it corresponds to in the function definition.  **Keyword arguments** are arguments that are passed to a function by explicitly naming each parameter and assigning a value. The order of arguments doesn’t matter as each argument is specified by its parameter name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0f3ad-4353-473b-8073-c2bc1a383252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name, message):\n",
    "    print(f\"{message}, {name}!\")\n",
    "\n",
    "# Positional arguments\n",
    "greet(\"Alice\", \"Hello\")\n",
    "\n",
    "# Keyword arguments\n",
    "greet(name=\"Alice\", message=\"Hello\")\n",
    "greet(message=\"Goodbye\", name=\"Bob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb791921-b413-49c7-aec7-ad5e60c16292",
   "metadata": {},
   "source": [
    "## Default arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836e0100-05eb-4fac-80db-f7f39197ba8d",
   "metadata": {},
   "source": [
    "Default arguments in Python are a way to specify default values for function parameters. If a function call does not provide a value for a parameter with a default value, the default value is used. This allows for more flexible and concise function definitions and calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c01ce-a0cd-4827-bdf9-5accf02f514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name, message=\"Hello\"):\n",
    "    print(f\"{message}, {name}!\")\n",
    "\n",
    "# Function call with both arguments\n",
    "greet(\"Alice\", \"Good morning\")  # Output: Good morning, Alice!\n",
    "\n",
    "# Function call with only the required argument\n",
    "greet(\"Bob\")  # Output: Hello, Bob!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eafc09-d2da-419b-8b62-4ce2d2c8f5fe",
   "metadata": {},
   "source": [
    "Using mutable objects as default arguments can lead to unexpected behavior because the default value is shared across all calls to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24465745-d2b4-40e6-a768-b58e78eed0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_list(value, my_list=[]):\n",
    "    my_list.append(value)\n",
    "    return my_list\n",
    "\n",
    "# The list is shared between calls\n",
    "print(append_to_list(1))  # Output: [1]\n",
    "print(append_to_list(2))  # Output: [1, 2]\n",
    "print(append_to_list(3))  # Output: [1, 2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3333be6-3140-4470-b340-bb1367209796",
   "metadata": {},
   "source": [
    "## Args and Kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6e144-d341-4240-bc2d-0a77de1d39fd",
   "metadata": {},
   "source": [
    "The concepts of *args and **kwargs in Python are used for passing a variable number of arguments to a function. They provide flexibility in function calls, allowing you to handle an arbitrary number of positional and keyword arguments.\n",
    "- *args: Used to pass a variable number of positional arguments to a function. These arguments are accessible as a tuple.\n",
    "- **kwargs: Used to pass a variable number of keyword arguments to a function. These arguments are accessible as a dictionary.\n",
    "- Combination: Both can be used together to create highly flexible functions that can handle any number of positional and keyword arguments.\n",
    "- Order: When used together, *args should come before **kwargs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c88038-4201-4b01-84a5-2c1884c9c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example(pos1, pos2, *args, kw1=None, kw2=None, **kwargs):\n",
    "    print(f\"pos1: {pos1}, pos2: {pos2}\")\n",
    "    print(f\"kw1: {kw1}, kw2: {kw2}\")\n",
    "    print(f\"args: {args}\")\n",
    "    print(f\"kwargs: {kwargs}\")\n",
    "\n",
    "example(1, 2, 3, 4, kw1='a', extra='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1735c11-5c29-456a-a109-e4f2d822ff79",
   "metadata": {},
   "source": [
    "When defining a function with *args and **kwargs, the order of parameters should be:\n",
    "\n",
    "- Positional arguments (required)\n",
    "- *args: It collects additional positional arguments passed to the function into a tuple.\n",
    "- Keyword arguments (optional)\n",
    "- **kwargs: These arguments are accessible as a dictionary within the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e362503-29cd-4dbe-a12b-bad54c191109",
   "metadata": {},
   "source": [
    "## Unpacking arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938634e3-6bf2-493a-aa96-9dbc60eb9ab1",
   "metadata": {},
   "source": [
    "We already discussed unpacking using tuples, when we return values, but there is the possibility to pass a list of variables as a function parameter using the asterisk operator. Keep in mind. that the length of the container must match the number of parameters, as well as the type of variables. Unpacking will always be done in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee00637d-c32d-462f-9af0-5fcdb550e969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(a, b, c):\n",
    "    print(a, b, c)\n",
    "\n",
    "my_list=[0, 1, 2]\n",
    "foo(*my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4667f5-265a-4572-adea-31fd1de980c2",
   "metadata": {},
   "source": [
    "## Local vs Global variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f95cbc-963c-458e-921f-7c440d85ebcd",
   "metadata": {},
   "source": [
    "*Local variables* = Local variables are variables that are declared within a function and are only accessible within that function. Their scope is limited to the function in which they are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048ab1fe-2a2a-4fe6-8f41-cbe1ecd297a8",
   "metadata": {},
   "source": [
    "*Global variables* = Global variables are variables that are declared outside of all functions and are accessible throughout the entire script. Their scope extends to the entire script, and they can be accessed from within any function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3299c4b2-6d28-4086-9741-7f5130bf29c2",
   "metadata": {},
   "source": [
    "| Aspect           | Local Variables                                | Global Variables                               |\n",
    "|------------------|------------------------------------------------|-----------------------------------------------|\n",
    "| **Definition**   | Declared within a function or namespace        | Declared outside all functions.               |\n",
    "| **Scope**        | Accessible only within the function.           | Accessible throughout the entire script.      |\n",
    "| **Lifetime**     | Exists only during the function execution.     | Exists for the duration of the program's execution. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b517b5-67f1-4674-a8dd-6af32859bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar():\n",
    "    number = 3\n",
    "    print('number inside function: ', x)\n",
    "\n",
    "number = 0\n",
    "bar()\n",
    "print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc789a0-6b90-46dd-9975-6d4c1527d370",
   "metadata": {},
   "source": [
    "## Passing parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a966520-20d6-4442-a37d-a8781182d079",
   "metadata": {},
   "source": [
    "In call by value, a copy of the actual parameter's value is passed to the function. Changes made to the parameter inside the function do not affect the original variable. In call by reference, a reference to the actual parameter is passed to the function. Changes made to the parameter inside the function affect the original variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac869fc0-3d61-4b22-8667-8b8a72e13e59",
   "metadata": {},
   "source": [
    "There are two rules that have to be considered. Parameters parsed in is a reference, but the reference is passes by value. Also, there is a difference between mutable and inmutable data types: mutable object types can be changed withing a function, but if you rebind the reference within a method, the outside reference will not be affected. Furthermore, although inmutable object cannot be modified within a method, a reference of the inmutable object can be reassigned within a mutable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75fb037-37f1-4a9e-bc36-ab155099bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ool(a_list):\n",
    "    a_list = [200, 300, 400]\n",
    "    a_list.append(4)\n",
    "    a_list[0] = -100\n",
    "\n",
    "a_list = [1, 2, 3, 4]\n",
    "ool(a_list)\n",
    "print(a_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ddc7fd-9af5-4a23-9b21-932de0bb9a2f",
   "metadata": {},
   "source": [
    "# Shallow vs Deep copying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e3083-ba03-4396-8115-db9c18e48cc6",
   "metadata": {},
   "source": [
    "The built-in copy module in Python provides functions to create shallow and deep copies of objects. This is particularly useful when you want to duplicate complex objects like lists, dictionaries, or user-defined classes, but the way the copies are made can have significant implications for how the original and copied objects interact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c5fc7-dc00-44df-82f0-c830c9021336",
   "metadata": {},
   "source": [
    "A **shallow copy** creates a new object, but it inserts references into it to the objects found in the original. Therefore, if the original object contains references to mutable objects (like lists or dictionaries), both the original and the shallow copy will refer to the same mutable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d95fa-36ef-4d9e-93ad-8bd96c129fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "org = [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
    "\n",
    "# On the second level both will be affected\n",
    "cpy = copy.copy(org)\n",
    "cpy[0][1] = -100\n",
    "\n",
    "print(org)\n",
    "print(cpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c04d7e4-5c5e-4b5d-85fc-a334d12bd9f1",
   "metadata": {},
   "source": [
    "A **deep copy** creates a new object and recursively copies all objects found in the original, meaning that it creates a completely independent copy of the entire structure. This means that modifications to the original object do not affect the deep copy, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cb532-b015-4807-a0fe-947336444fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There references are duplicated as well\n",
    "cpy = copy.deepcopy(org)\n",
    "cpy[0][1] = 0\n",
    "\n",
    "print(org)\n",
    "print(cpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45fe72c-327b-4a28-90c1-d86fe4f60318",
   "metadata": {},
   "source": [
    "| Aspect                    | Shallow Copy                                                      | Deep Copy                                                      |\n",
    "|---------------------------|-------------------------------------------------------------------|----------------------------------------------------------------|\n",
    "| **Definition**            | Creates a new object but copies references to nested objects.     | Creates a new object and recursively copies all nested objects. |\n",
    "| **Usage of Memory**       | Less memory is used since nested objects are shared.              | More memory is used since all objects are copied.               |\n",
    "| **Impact of Modifications**| Changes in mutable objects are reflected in both original and copied objects. | Changes in the original do not affect the deep copy and vice versa. |\n",
    "| **Function**              | `copy.copy()`                                                     | `copy.deepcopy()`                                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ee6488-97f4-4fc1-b7ed-9c3877751374",
   "metadata": {},
   "source": [
    "# Contex Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad8845-752c-4209-b06b-7105976c3b73",
   "metadata": {},
   "source": [
    "Context managers in Python are constructs that allow for the allocation and release of resources precisely when you need them. They are a great tool for resource management, as they allow to allocate resources efficiently, and offer a cleaner code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898001c0-dd7c-46af-b9c6-cc872bf78c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for the whole process\n",
    "file = open('notes.txt', 'w')\n",
    "try:\n",
    "    file.write('some todoo...')\n",
    "finally:\n",
    "    file.close()\n",
    "\n",
    "# Code with context managers\n",
    "with open('notes.txt', 'w') as file:\n",
    "    file.write('This is a file context manager')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21edf644-7115-4f0b-9e58-b2e1ee0a8aca",
   "metadata": {},
   "source": [
    "**Benefits of Using Context Managers:**\n",
    "- *Resource Management:* Ensures that resources like files, network connections, and locks are properly managed, avoiding resource leaks.\n",
    "- *Error Handling:* Automatically handles exceptions and ensures cleanup code is executed.\n",
    "- *Readability:* Provides a clean and readable way to manage resources, reducing boilerplate code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c83614-7d5e-4ba4-a852-3d1d31ad4698",
   "metadata": {},
   "source": [
    "## Wrinting custom context manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2fc75-4f3f-4593-9db7-e793b3956707",
   "metadata": {},
   "source": [
    "You can write custom context managers in Python by implementing two special methods: __enter__ and __exit__.\n",
    "- __enter__ Method: Executed when the execution flow enters the context of the with statement. It can return an object to be used within the with block.\n",
    "- __exit__ Method: Executed when the execution flow leaves the context of the with statement. It can handle exceptions, taking three arguments (exc_type, exc_val, exc_tb) that describe the exception, if any. Returning True suppresses the exception, while returning False propagates it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739f545-a7f7-4fce-984b-0b2bb9df4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomContextManager:\n",
    "    def __enter__(self):\n",
    "        # Code to acquire resource\n",
    "        print(\"Entering the context\")\n",
    "        return self  # This is optional, depends on what you need\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        # Code to release resource\n",
    "        print(\"Exiting the context\")\n",
    "        # Handle exceptions if necessary\n",
    "        # Return True to suppress the exception, or False to propagate it\n",
    "        return False\n",
    "\n",
    "# Usage\n",
    "with CustomContextManager() as manager:\n",
    "    print(\"Inside the context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b339d4-aab0-4f91-ac1f-c6b91c01713c",
   "metadata": {},
   "source": [
    "Alternatively, you can use the contextlib module, which provides a decorator for simpler context manager creation.\n",
    "\n",
    "- contextlib.contextmanager Decorator: A simpler way to create context managers using a generator function, where the setup code goes before the yield and the cleanup code goes after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3966e14-4a03-4568-8bc6-a1f069fc58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def custom_context():\n",
    "    try:\n",
    "        # Code to acquire resource\n",
    "        print(\"Entering the context\")\n",
    "        yield\n",
    "    finally:\n",
    "        # Code to release resource\n",
    "        print(\"Exiting the context\")\n",
    "\n",
    "# Usage\n",
    "with custom_context():\n",
    "    print(\"Inside the context\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
