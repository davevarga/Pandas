{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66b22aa4-4cbc-41a4-876a-34a5196e8910",
   "metadata": {},
   "source": [
    "# Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c02f82-c5ea-4e91-8b54-cccb44c991fd",
   "metadata": {},
   "source": [
    "Generators are function that return an object that can be iterated over. The special thing is that they generate the items inside the object lazily, which means they generate the items only one at a time and only when you ask for it. And because of this, they are much more memory efficient than other sequence objects when you have to deal with large data sets. They are a powerful advanced Python technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab9df93-6b5b-4068-8e0e-80615e45ef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def mygenerator():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3\n",
    "\n",
    "for i in mygenerator():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3b86a-d21a-4117-aeba-8c8fdf95aa4b",
   "metadata": {},
   "source": [
    "Let's have a closer look at the execution. This can be visualized by another generator. The generator is memory efficient because, instead of predefining the values of an iterable collection, it gives the possibility to calculate a value of an index when it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "209da9a9-64eb-4216-a46f-f1779d8f63dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8448728\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Lists object generator\n",
    "def firstn(n):\n",
    "    nums = []\n",
    "    num = 0\n",
    "    while num < n:\n",
    "        nums.append(num)\n",
    "        num+=1\n",
    "    return nums\n",
    "\n",
    "# Generator object of collection\n",
    "def firstn_generator(n):\n",
    "    num = 0\n",
    "    while num < n:\n",
    "        yield num\n",
    "        num += 1\n",
    "\n",
    "print(sys.getsizeof(firstn(1000000)))\n",
    "print(sys.getsizeof(firstn_generator(1000000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130ce0b-8f15-4dae-b95c-39f19b13814e",
   "metadata": {},
   "source": [
    "We can see that a generator is orders of magnitude more efficient. Furthermore, we don't have to wait for the operating system to read all the data into the memory before we can use the collection, so it is faster as well. Consequently, generators are very handy, when the collection data can be determined from known patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454ee0ec-d3f9-4780-b0bc-97c02cbe4e3d",
   "metadata": {},
   "source": [
    "Generator expressions are handier still. They are written like list comprehensions, but with parentheses instead of square brackets. It is a very simple syntax and shortcut to implement the generator expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aaade377-b596-47c2-9782-2d84cb572f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of generator is:  208\n",
      "Size of list is:  444376\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Using expression as generator definition\n",
    "mygenerator = (i for i in range(100000) if i % 2 == 0)\n",
    "print(\"Size of generator is: \", sys.getsizeof(mygenerator))\n",
    "\n",
    "# Using expression as list definition\n",
    "mylist = [i for i in range(100000) if i % 2 == 0]\n",
    "print(\"Size of list is: \", sys.getsizeof(mylist))\n",
    "\n",
    "sum = 0\n",
    "for i in mygenerator:\n",
    "    sum += 1\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ad6e1c-c7f5-4718-b2ae-a1b03e7360b7",
   "metadata": {},
   "source": [
    "# Threading vs Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8df7952-e85e-4cdc-841d-99db094f6d35",
   "metadata": {},
   "source": [
    "## Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba92ee16-174d-4728-b19d-c148cf70262f",
   "metadata": {},
   "source": [
    "A thread is an entity within a process that can be scheduled for execution. All threads within a process share the same memory space, which allows them to communicate quickly but also requires careful management to avoid conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df92caa-9d63-4a8c-a236-4ac74085b1b9",
   "metadata": {},
   "source": [
    "| Pros                                         | Explanation                                                                                     | Cons                                    | Explanation                                                                                     |\n",
    "|----------------------------------------------|--------------------------------------------------------------------------------------------------|-----------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| All threads within a process share the same memory | This allows threads to communicate quickly and share data easily.                                | Threading is limited by GIL: Only one thread at a time | In Python, the Global Interpreter Lock (GIL) means that only one thread can execute Python bytecode at a time, limiting concurrency. |\n",
    "| Lightweight                                  | Threads use fewer resources and less overhead than processes.                                    | No effect for CPU-bound tasks           | For CPU-bound tasks, threads do not provide performance improvements due to the GIL.             |\n",
    "| Starting a thread is faster than starting a process | Creating a thread incurs less overhead compared to creating a process.                           | Not interruptable/killable              | Threads cannot be forcibly terminated from the outside; they must complete their task.           |\n",
    "| Great for I/O-bound tasks                    | Threads can handle multiple I/O operations concurrently, improving performance.                  | Careful with race conditions            | Shared memory access can lead to race conditions if not managed properly.                        |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a94f95-dd68-43f0-88ee-26361668d6d1",
   "metadata": {},
   "source": [
    "**When to Use Threads:**\n",
    "\n",
    "- *I/O-bound tasks:* Threads are excellent for tasks that spend a lot of time waiting for I/O operations, such as reading from a disk, network communication, or user inputs.\n",
    "- *Lightweight operations:* When you need to perform many small tasks simultaneously, threads are more efficient because they require less overhead to create and manage.\n",
    "- *Quick startup time:* If your application needs to start many parallel tasks quickly, threads are advantageous due to their fast startup time compared to processes.\n",
    "\n",
    "**Avoid Threads:**\n",
    "\n",
    "- *CPU-bound tasks:* Due to the Global Interpreter Lock (GIL) in Python, threads are not suitable for CPU-bound tasks because only one thread can execute Python code at a time.\n",
    "- *High control needs:* If you need to be able to forcibly stop a task, threads are not ideal since they cannot be interrupted or killed externally.\n",
    "- *Complex synchronization:* If your tasks require complex sharing and synchronization of data, the potential for race conditions and the complexity of managing thread safety might outweigh the benefits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b346dd47-399a-4048-9f0e-45fe23659c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end main\n"
     ]
    }
   ],
   "source": [
    "# Import the basic threading library\n",
    "from threading import Thread\n",
    "import os\n",
    "import time\n",
    "\n",
    "# A good number of processes is the number of threads\n",
    "threads = []\n",
    "num_threads = 10\n",
    "\n",
    "# We have to define a function to use a process\n",
    "def square_numbers():\n",
    "    for i in range(100):\n",
    "        i * i\n",
    "\n",
    "# Assigning process to the function\n",
    "for i in range(num_threads):\n",
    "    t = Thread(target=square_numbers)\n",
    "    threads.append(t)\n",
    "\n",
    "# Start each thread\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# Block the main thread until the processes are finished\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "print('end main')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04277a82-7105-4a4b-9245-13802cf21bf1",
   "metadata": {},
   "source": [
    "Since threads live in the same memory space, sharing data is easy. We can do it in Python using a global variable. This variable simulates a database. We have to be careful through, as database integrity can be easily affected by interferennce. Therefore we have to use syncronization methods. For this special locks are used before and after processing the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb4824-d8d5-4160-a6ba-f36b43f5dc48",
   "metadata": {},
   "source": [
    "In addition a queue can be used for data interference. A queue is a linear data structure similar to a FIFO. This avoids discriminating threads from getting the lock. Note that any input or output stream has to be used as a database as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5f0c40a9-5c57-4e5c-9c77-370135b139db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End value of database:  2\n"
     ]
    }
   ],
   "source": [
    "# Import special type for lock\n",
    "from threading import Lock\n",
    "\n",
    "database_value = 0\n",
    "\n",
    "def increase(lock):\n",
    "    global database_value\n",
    "\n",
    "    # Another thread cannot have it the same time\n",
    "    with lock:\n",
    "        local_copy = database_value\n",
    "        local_copy += 1\n",
    "        time.sleep(0.03)\n",
    "        database_value = local_copy\n",
    "\n",
    "# Creating threads\n",
    "lock = Lock()\n",
    "thread1 = Thread(target=increase, args=(lock,))\n",
    "thread2 = Thread(target=increase, args=(lock,))\n",
    "\n",
    "# Starting threads\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "\n",
    "# Stopping threads\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "\n",
    "print(\"End value of database: \", database_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e87838-89c4-4b35-8317-e3caa33f54ff",
   "metadata": {},
   "source": [
    "While the main thread is the initial thread of execution in any Python program, as when a Python script starts, a single main thread is created by default, the daemon thread is a type of thread that runs in the background and is typically used for tasks that should not block the program from exiting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d724f83-567d-4b4b-adc2-ecacbf28a080",
   "metadata": {},
   "source": [
    "| Aspect           | Main Thread                                              | Daemon Thread                                            |\n",
    "|------------------|----------------------------------------------------------|----------------------------------------------------------|\n",
    "| **Role**         | Handles the primary logic and essential tasks.           | Handles background tasks like logging and monitoring.    |\n",
    "| **Lifecycle**    | Program runs until the main thread finishes.             | Program exits when only daemon threads are left running. |\n",
    "| **Termination**  | Prevents program from exiting until it completes.        | Does not prevent program from exiting.                   |\n",
    "| **Creation**     | Automatically created when the program starts.           | Created by setting `daemon` attribute to `True` before starting the thread. |\n",
    "| **Usage**        | Used for core application logic and critical operations. | Used for periodic or auxiliary tasks that can terminate abruptly. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5c86a-e533-4dc2-b8dc-84aaeffa6a7c",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64966d35-5c54-428e-8d0f-f3e50eca3a64",
   "metadata": {},
   "source": [
    "A process is an instance of a program running in its own memory space. Each process is independent and isolated from others, which provides stability and security but requires more resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9759e3-5428-4453-be78-0d0a399f9483",
   "metadata": {},
   "source": [
    "| Pros                                               | Explanation                                                                                     | Cons                                               | Explanation                                                                                     |\n",
    "|----------------------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------------------------------|--------------------------------------------------------------------------------------------------|\n",
    "| Takes advantage of multiple CPUs and cores         | Processes can run on different CPUs or cores, providing true parallelism.                       | Heavyweight                                        | Processes use more system resources and are heavier than threads.                               |\n",
    "| Separate memory space -> Memory is not shared between processes | Each process has its own memory space, which enhances stability and security.                   | Starting a process is slower than starting a thread | Creating a new process takes more time and resources compared to a thread.                      |\n",
    "| Great for CPU-bound processing                     | Processes can fully utilize multiple cores for CPU-intensive tasks.                             | More memory                                        | Each process requires its own memory allocation, leading to higher memory usage.                |\n",
    "| New process is started independently from other processes | Processes are isolated, so the failure of one does not affect others.                            | IPC (inter-process communication) is more complicated | Communicating between processes is more complex and requires additional mechanisms.              |\n",
    "| Processes are interruptable/killable               | Processes can be terminated externally, allowing for better control.                            |                                                    |                                                                                                  |\n",
    "| One GIL for each process -> avoids GIL limitation  | Each process has its own GIL, so they can run Python code concurrently.                         |                                                    |                                                                                                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e8c757-ba71-4b15-97a3-50fb710a1ad8",
   "metadata": {},
   "source": [
    "**When to Use Processes:**\n",
    "\n",
    "- *CPU-bound tasks:* Processes can fully utilize multiple CPU cores because each process runs independently and has its own Python interpreter and GIL.\n",
    "- *Memory isolation:* If you need tasks to run in isolated memory spaces to avoid conflicts and improve stability, processes are the better choice.\n",
    "- *Parallel execution:* For true parallel execution on multiple cores, processes are necessary.\n",
    "\n",
    "**Avoid Processes:**\n",
    "\n",
    "- *I/O-bound tasks:* The overhead of creating and managing processes can be too high for tasks that spend a lot of time waiting for I/O operations.\n",
    "- *Resource efficiency:* If you need to run many tasks simultaneously with minimal overhead, the resource demands of processes may be too high.\n",
    "- *Complex IPC:* Communication between processes is more complicated than between threads, which can add complexity to your application if frequent inter-process communication is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "31b72b91-1ea2-4eb9-9aa4-8460aa09960b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end main\n"
     ]
    }
   ],
   "source": [
    "# basic multiprocessing library\n",
    "from multiprocessing import Process\n",
    "\n",
    "# A good number of processes is the number of cores\n",
    "processes = []\n",
    "num_processes = os.cpu_count()\n",
    "\n",
    "# Assigning process to the function\n",
    "for i in range(num_processes):\n",
    "    p = Process(target=square_numbers)\n",
    "    processes.append(p)\n",
    "    p.start()\n",
    "\n",
    "# Block the main thread until the processes are finished\n",
    "for p in processes:\n",
    "    p.join()\n",
    "\n",
    "print('end main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6cb605-2ee3-4531-8d96-bd10bfd904b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
